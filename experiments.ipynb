{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQwlunyE86kE"
      },
      "source": [
        "# 1. Вычисления на GPU. Проект: ускорение инференса нейросети\n",
        "\n",
        "**ФИО**: Хоружев Илья Максимович"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Будем по картинке определять одежду с помощью самописной нейросети"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'NVIDIA GeForce RTX 4070'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "torch.cuda.get_device_name(\"cuda:0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UyCGfNgA86kF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from torch import nn\n",
        "from torch.autograd import Function\n",
        "from torch.autograd import gradcheck\n",
        "from torch.optim import Optimizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LauGpMvGF5qr"
      },
      "outputs": [],
      "source": [
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "snTBHRTQI1bc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def load_mnist(path, kind='train'):\n",
        "    import os\n",
        "    import gzip\n",
        "    import numpy as np\n",
        "\n",
        "    \"\"\"Load MNIST data from `path`\"\"\"\n",
        "    labels_path = os.path.join(path,\n",
        "                               '%s-labels-idx1-ubyte.gz'\n",
        "                               % kind)\n",
        "    images_path = os.path.join(path,\n",
        "                               '%s-images-idx3-ubyte.gz'\n",
        "                               % kind)\n",
        "\n",
        "    with gzip.open(labels_path, 'rb') as lbpath:\n",
        "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
        "                               offset=8)\n",
        "\n",
        "    with gzip.open(images_path, 'rb') as imgpath:\n",
        "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
        "                               offset=16).reshape(len(labels), 784)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "class FashionMnist(Dataset):\n",
        "    def __init__(self, path, train=True, image_transform=None,\n",
        "                 label_transform=None):\n",
        "        if train:\n",
        "            images, labels = load_mnist(os.path.join(path,\"raw\"))\n",
        "        else:\n",
        "            images, labels = load_mnist(os.path.join(path,\"raw\"), kind=\"t10k\")\n",
        "        \n",
        "        if image_transform is not None:\n",
        "            self._images = image_transform(images.astype(np.float32))\n",
        "        else:\n",
        "            self._images = images.astype(np.float32)\n",
        "        \n",
        "        if label_transform is not None:  \n",
        "            self._labels = label_transform(labels)\n",
        "        else:\n",
        "            self._labels = labels\n",
        "\n",
        "    def __len__(self,):\n",
        "        return len(self._labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self._images[idx].reshape((28, 28))\n",
        "        label = self._labels[idx]\n",
        "        \n",
        "        return img, label\n",
        "\n",
        "test_dataset = FashionMnist(\"data/FashionMNIST\", train=False)\n",
        "train_dataset = FashionMnist(\"data/FashionMNIST\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JciETIfndiGR"
      },
      "source": [
        "Визуализируйте случайные элементы набора данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wBky4UtmOS71"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "classes = {\n",
        "    0: \"T-shirt/top\", \n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle boot\"\n",
        "}\n",
        "\n",
        "ind = np.random.randint(len(train_dataset))\n",
        "\n",
        "plt.imshow(train_dataset[ind][0])\n",
        "plt.title(classes[train_dataset[ind][1]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7BpFQ_Y2PoeI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_4478/2421384196.py:5: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1695627723575/work/torch/csrc/utils/tensor_numpy.cpp:206.)\n",
            "  return torch.from_numpy(sample)\n"
          ]
        }
      ],
      "source": [
        "class ToTensor:\n",
        "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        return torch.from_numpy(sample)\n",
        "\n",
        "transform = ToTensor()\n",
        "\n",
        "test_dataset = FashionMnist(\"data/FashionMNIST\",\n",
        "                            train=False,\n",
        "                            image_transform=transform,\n",
        "                            label_transform=transform\n",
        "                            )\n",
        "train_dataset = FashionMnist(\"data/FashionMNIST\",\n",
        "                             image_transform=transform,\n",
        "                             label_transform=transform\n",
        "                             )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4dDtlvlCXNbW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The length of the batch is 2\n",
            "The shape of the batch[0] is torch.Size([15, 784])\n"
          ]
        }
      ],
      "source": [
        "def collate(batch):\n",
        "    imgs = torch.tensor([(item[0].ravel() / 255).tolist() for item in batch])\n",
        "    labels = torch.tensor([item[1].tolist() for item in batch])\n",
        "    \n",
        "    return imgs, labels\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=15, num_workers=2,\n",
        "                             shuffle=True, collate_fn=collate)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=15, num_workers=2,\n",
        "                              shuffle=True, collate_fn=collate)\n",
        "batch = next(iter(test_dataloader))\n",
        "\n",
        "print(f\"The length of the batch is {len(batch)}\")\n",
        "print(f\"The shape of the batch[0] is {batch[0].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from neural_net import Network, CrossEntropy\n",
        "from training import perform_epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtamPEJZgOY5"
      },
      "source": [
        "Теперь обучим нашу нейронную сеть c разными размерностями скрытых слоев (32, 128, 512, 1024, 1532)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:04<00:00, 824.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch - 0 : loss 0.5383268827819265, accuracy 0.8060328960418701\n",
            "Current learning rate: 0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:04<00:00, 859.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch - 1 : loss 0.400562827116577, accuracy 0.8556509613990784\n",
            "Current learning rate: 0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:04<00:00, 839.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch - 2 : loss 0.36788649309135507, accuracy 0.865666389465332\n",
            "Current learning rate: 0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model32 = Network(num_layers=4, dropout_prob=0, hidden_layers_size=32)\n",
        "optimizer = torch.optim.Adam(model32.parameters())\n",
        "criterion = CrossEntropy()\n",
        "\n",
        "device = 'cpu'\n",
        "\n",
        "model32.to(device)\n",
        "\n",
        "for epoch in range(3):\n",
        "    loss, acc = perform_epoch(model32, train_dataloader, criterion,\n",
        "                                optimizer=optimizer, device=device)\n",
        "    print(f\"Epoch - {epoch} : loss {loss}, accuracy {acc}\")\n",
        "    print(f\"Current learning rate: {optimizer.param_groups[0]['lr']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Network(\n",
              "  (activations): ModuleDict(\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(784, 32)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(32, 32)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(32, 32)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(32, 10)\n",
              "    (7): LogSoftmax()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model32.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.11 s ± 77.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_data, batch_labels in train_dataloader:\n",
        "        model_labels = model32(batch_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Загрузим веса в класс для инференса"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from inference_cuda import NeuralNetworkCUDA\n",
        "\n",
        "weights = [x.detach().numpy() for x in model32.parameters() if len(x.shape) == 2]\n",
        "biases = [x.detach().numpy() for x in model32.parameters() if len(x.shape) == 1]\n",
        "\n",
        "inference_model = NeuralNetworkCUDA(784, 10, 32)\n",
        "inference_model.load_model(weights, biases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.37 s ± 31.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "\n",
        "for batch_data, batch_labels in train_dataloader:\n",
        "    model_labels = inference_model.apply(batch_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "на гпу дольше вычисляется из-за не самойэффективной реализации "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:05<00:00, 711.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch - 0 : loss 0.48991525602107866, accuracy 0.8260159492492676\n",
            "Current learning rate: 0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:05<00:00, 730.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch - 1 : loss 0.3765409529886674, accuracy 0.8623170852661133\n",
            "Current learning rate: 0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:05<00:00, 734.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch - 2 : loss 0.34027606404596006, accuracy 0.8747332096099854\n",
            "Current learning rate: 0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model128     = Network(num_layers=4, dropout_prob=0, hidden_layers_size=128)\n",
        "optimizer = torch.optim.Adam(model128.parameters())\n",
        "criterion = CrossEntropy()\n",
        "\n",
        "device = 'cpu'\n",
        "\n",
        "model128.to(device)\n",
        "\n",
        "for epoch in range(3):\n",
        "    loss, acc = perform_epoch(model128, train_dataloader, criterion,\n",
        "                                optimizer=optimizer, device=device)\n",
        "    print(f\"Epoch - {epoch} : loss {loss}, accuracy {acc}\")\n",
        "    print(f\"Current learning rate: {optimizer.param_groups[0]['lr']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Network(\n",
              "  (activations): ModuleDict(\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(784, 128)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(128, 128)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(128, 128)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(128, 10)\n",
              "    (7): LogSoftmax()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model128.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.15 s ± 26.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_data, batch_labels in train_dataloader:\n",
        "        model_labels = model128(batch_data.to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "weights = [x.detach().numpy() for x in model128.parameters() if len(x.shape) == 2]\n",
        "biases = [x.detach().numpy() for x in model128.parameters() if len(x.shape) == 1]\n",
        "\n",
        "inference_model = NeuralNetworkCUDA(784, 10, 128)\n",
        "inference_model.load_model(weights, biases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.33 s ± 15.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "\n",
        "for batch_data, batch_labels in train_dataloader:\n",
        "    model_labels = inference_model.apply(batch_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "на гпу все еще дольше"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:10<00:00, 397.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch - 0 : loss 0.49283915635896847, accuracy 0.8212820887565613\n",
            "Current learning rate: 0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:10<00:00, 364.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch - 1 : loss 0.3745171337302309, accuracy 0.8633339405059814\n",
            "Current learning rate: 0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:10<00:00, 372.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch - 2 : loss 0.3415282298647799, accuracy 0.8741332292556763\n",
            "Current learning rate: 0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model512     = Network(num_layers=4, dropout_prob=0, hidden_layers_size=512)\n",
        "optimizer = torch.optim.Adam(model512.parameters())\n",
        "criterion = CrossEntropy()\n",
        "\n",
        "device = 'cpu'\n",
        "\n",
        "model512.to(device)\n",
        "\n",
        "for epoch in range(3):\n",
        "    loss, acc = perform_epoch(model512, train_dataloader, criterion,\n",
        "                                optimizer=optimizer, device=device)\n",
        "    print(f\"Epoch - {epoch} : loss {loss}, accuracy {acc}\")\n",
        "    print(f\"Current learning rate: {optimizer.param_groups[0]['lr']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Network(\n",
              "  (activations): ModuleDict(\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(784, 512)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(512, 512)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(512, 512)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(512, 10)\n",
              "    (7): LogSoftmax()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model512.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.35 s ± 65.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_data, batch_labels in train_dataloader:\n",
        "        model_labels = model512(batch_data.to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "weights = [x.detach().numpy() for x in model512.parameters() if len(x.shape) == 2]\n",
        "biases = [x.detach().numpy() for x in model512.parameters() if len(x.shape) == 1]\n",
        "\n",
        "inference_model = NeuralNetworkCUDA(784, 10, 512)\n",
        "inference_model.load_model(weights, biases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.34 s ± 22.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "\n",
        "for batch_data, batch_labels in train_dataloader:\n",
        "    model_labels = inference_model.apply(batch_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Вычисление на cpu сравнялось с вычислением на гпу"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:32<00:00, 125.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch - 0 : loss 0.5019309280186426, accuracy 0.8161828517913818\n",
            "Current learning rate: 0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:31<00:00, 128.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch - 1 : loss 0.38197320134425533, accuracy 0.8612012267112732\n",
            "Current learning rate: 0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:30<00:00, 130.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch - 2 : loss 0.3442518028831109, accuracy 0.8748324513435364\n",
            "Current learning rate: 0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model1024     = Network(num_layers=4, dropout_prob=0, hidden_layers_size=1024)\n",
        "optimizer = torch.optim.Adam(model1024.parameters())\n",
        "criterion = CrossEntropy()\n",
        "\n",
        "device = 'cpu'\n",
        "\n",
        "model1024.to(device)\n",
        "\n",
        "for epoch in range(3):\n",
        "    loss, acc = perform_epoch(model1024, train_dataloader, criterion,\n",
        "                                optimizer=optimizer, device=device)\n",
        "    print(f\"Epoch - {epoch} : loss {loss}, accuracy {acc}\")\n",
        "    print(f\"Current learning rate: {optimizer.param_groups[0]['lr']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Network(\n",
              "  (activations): ModuleDict(\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(784, 1024)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(1024, 1024)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(1024, 1024)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(1024, 10)\n",
              "    (7): LogSoftmax()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model1024.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.06 s ± 43.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_data, batch_labels in train_dataloader:\n",
        "        model_labels = model1024(batch_data.to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "weights = [x.detach().numpy() for x in model1024.parameters() if len(x.shape) == 2]\n",
        "biases = [x.detach().numpy() for x in model1024.parameters() if len(x.shape) == 1]\n",
        "\n",
        "inference_model = NeuralNetworkCUDA(784, 10, 1024)\n",
        "inference_model.load_model(weights, biases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.29 s ± 8.91 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "\n",
        "for batch_data, batch_labels in train_dataloader:\n",
        "    model_labels = inference_model.apply(batch_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:59<00:00, 67.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch - 0 : loss 0.5145789016648196, accuracy 0.817065954208374\n",
            "Current learning rate: 0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:59<00:00, 67.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch - 1 : loss 0.3870886690532789, accuracy 0.859600841999054\n",
            "Current learning rate: 0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:59<00:00, 67.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch - 2 : loss 0.3523322514698375, accuracy 0.8709164261817932\n",
            "Current learning rate: 0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model1532     = Network(num_layers=4, dropout_prob=0, hidden_layers_size=1532)\n",
        "optimizer = torch.optim.Adam(model1532.parameters())\n",
        "criterion = CrossEntropy()\n",
        "\n",
        "device = 'cpu'\n",
        "\n",
        "model1532.to(device)\n",
        "\n",
        "for epoch in range(3):\n",
        "    loss, acc = perform_epoch(model1532, train_dataloader, criterion,\n",
        "                                optimizer=optimizer, device=device)\n",
        "    print(f\"Epoch - {epoch} : loss {loss}, accuracy {acc}\")\n",
        "    print(f\"Current learning rate: {optimizer.param_groups[0]['lr']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Network(\n",
              "  (activations): ModuleDict(\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(784, 1532)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(1532, 1532)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(1532, 1532)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(1532, 10)\n",
              "    (7): LogSoftmax()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model1532.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.58 s ± 141 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_data, batch_labels in train_dataloader:\n",
        "        model_labels = model1532(batch_data.to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "weights = [x.detach().numpy() for x in model1532.parameters() if len(x.shape) == 2]\n",
        "biases = [x.detach().numpy() for x in model1532.parameters() if len(x.shape) == 1]\n",
        "\n",
        "inference_model = NeuralNetworkCUDA(784, 10, 1532)\n",
        "inference_model.load_model(weights, biases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.3 s ± 18.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "\n",
        "for batch_data, batch_labels in train_dataloader:\n",
        "    model_labels = inference_model.apply(batch_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Получилось, что при увеличении размерности нейростеи вычисления на гпу не замедляются, но на cpu заметно падает скорость инференса"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
